---
*layout*: post
title: Adaptive Module
---

## Overview
The adaptive module is that component of the application which provides individual users and, by extension, groups, with content which is attuned to their previous performance. For a detailed explanation of the basic adaptive module approach developed during the first semester of the project, please refer to the relevant chapter of the [implementation section]({{ "" | absolute_url }}/2020/05/02/implementation.html#adaptive). In this semester, we augmented the basic adaptive module by injecting user feedback and additional performance metadata. Justification and explanation of this so-called '*path* selection' module, including its supporting data sources, can be found in the following sections.

------

## Adaptive module weaknesses led to player self-regulation approach

### The missing scientific backing and unclear justification are the adaptive modules problems

Together with last semesters adaptive module we created an [evaluation of its validity]({{ "" | absolute_url }}/#). The evaluation concluded that the module would need further development in the second semester. The reasoning behind this conclusion was that its proficiency model relied to heavily on intuitive measures of difficulty and the modules goal of favoring the players weaknesses lacked a justification. In summary the problems of the module were:

1. the missing scientific backing for a positive learning impact,
2. the missing scientific backing for the item difficulty classification,
3. the missing justification for the prioritization of weak player categories,
4. that we missed any data for providing any of the above points.

### A shift of paradigm to player self-regulation neutralizes the problem

We noticed that other self-adjusting models suffer the same justification problem as our model, because the effectiveness of and justification for a self-adjusting adaptive module is too dependent on the specific circumstances of its application. This meant we either had to research our models effectiveness ourselves or circumvent this problem otherwise.

Our solution was to accompany the self-adjusting model as it is with a model using player self-regulation to influence difficulty adaption. Now the player themselves can intervene, if the difficulty level or category prioritization are not serving his learning goals.

Despite our change of approach, we still need to prove the positive learning impact of the adaption module. We address this need with a dedicated data collection module you can read about below and [extensive tests]({{ "" | absolute_url }}/#) this semester.

### The *path* selection choice after each task iteration is partially data driven

The first interaction a player has with the path selection module is after the first task. The player is asked to choose a new *path* to influence the further tasks. For the moment the player is provided with four options:

1. Increase all difficulties,
2. Decrease all difficulties,
3.  Focus on a single category,
4. Don't select a path.

While the first two options and the fourth are still generic we already choose the third option data driven. We would like to extend this data driven approach in future versions of the module.

### Each *path* can influence both the difficulty and the probability with which a category is chosen

Each *path* object consists out of  a `path_name`, an `path_id`, three dictionaries (`prof_dict`, `prob_dict`, `conditions`) and a boolean `set_prob` variable.

The `path_name` and the `path_id` are for identifying the path type.

The dictionary `prof_dict` encodes the change in proficiency the *path* is exerting.  For example the *increase all difficulties* *path* has the following dictionary: `{0.1 for all proficiencies in Vocabulary or Grammar}`. This means all proficiencies of the player are increased by 0.1 for this *path*.

The `prob_dict` dictionary encodes the change in probability the *path* is  exerting. For example the *focus on a single category* has the following dictionary: `{1 for chosen category; 0 for other categories in Vocabulary or Grammar}`. This means the only category that has any probability is the chosen one.

### The new process is kept totally compatible with the adaptive module

When a player chooses a *path* after a task, it is registered in a `path` list in the student object of the player.

During task item selection a category is selected. Either the probability is completely determined by the *path*. This happens, when a *path* has the `set_prob` attribute set to `True`. If this is the case only the last *path* with that property is valid and it dominates the probability distribution by setting its exact values. The second case is all *paths* have `set_prob = False`. Then the probabilities of a *path* are added to the existing probabilities and then these probabilities are normed. This happens in order of their acquisition for all *paths*.

Second a difficulty is selected. The players proficiency for the selected category is added by the values of each *path*. If the proficiency exceeds 10 or drops below 0 proficiency is kept constant. We proceed by balancing between category specific and domain average proficiency.

***

## Adaptive Data

To support the above-described *path* selection functionality we required additional user performance data in order to more-intelligently suggest possible *paths* to the users.

### General Approach

As outlined in the relevant chapters devoted to the sentence correction and vocabulary guessing tasks, both activities coordinate groups of users around a sequentially-progressive task by iterating over individual users as targeted activity leaders. In this way, each iteration is associated more-heavily with a particular user and can be inferred to be more relevant to his/her performance for the purposes of performance data collection. Given this assumption that each iteration can be associated directly with the elected participant, we record task iteration metadata and attribute these to the selected user as a measure of his/her success with the particular task item. For example, in a sentence correction task iteration in which one user is attempting to successfully-correct an erroneous sentence with the help of other users, the total time taken to complete the iteration is assumed to be indicative of the elected user's ability to resolve the presented sentence item and, by extension, informs suggested *paths* at the conclusion of all task iterations. 

In the below section we describe how this data collection procedure can be conceptualized at a higher level relevant to the backend application infrastructure.

### Technical Infrastructure and Further Details

The below diagram summarizes the adaptive module data collection protocol as it is integrated within the sequential task flow, with task iteration performance metadata collected during each user-association iteration before being stored to the PostgreSQL database at the end of the user's turn. At the end of all task iterations when the *path* selection options are presented, we retrieve previous user performance entries from the database and prioritize a dynamic third option based on the duration of previous task iterations associated with a specific sub-skill. In effect, that sub-skill which required the most time for a selected user to complete will determine the third option.

<img src="{{ '' | absolute_url }}/assets/images/adaptive_data_collection.png" class="center">

The below tables summarize the collected adaptive data for the two tasks.

<div>
    <table>
        <caption><b>Sentence Correction</b></caption>
        <tr>
            <th>Name</th>
            <th>Type</th>
            <th>Description</th>
        </tr>
        <tr>
            <td>id (PK)</td>
            <td>INTEGER</td>
            <td>Primary key.</td>
        </tr>
        <tr>
            <td>student_id (FK)</td>
            <td>INTEGER</td>
            <td>Student object primary key.</td>
        </tr>
        <tr>
            <td>group_id (FK)</td>
            <td>INTEGER</td>
            <td>Group object primary key.</td>
        </tr>
        <tr>
            <td>turn_start</td>
            <td>TIMESTAMP</td>
            <td>When the task iteration started.</td>
        </tr>
        <tr>
            <td>turn_duration</td>
            <td>INTERVAL</td>
            <td>Duration of the task iteration.</td>
        </tr>
        <tr>
            <td>performance</td>
            <td>INTEGER</td>
            <td>Number of task iteration phases successfully passed.</td>
        </tr>
        <tr>
            <td>messages_elected_user</td>
            <td>INTEGER</td>
            <td>Number of messages sent by elected user during the task iteration.</td>
        </tr>
        <tr>
            <td>messages_other_users</td>
            <td>INTEGER</td>
            <td>Number of messages sent by non-elected users during the task iteration.</td>
        </tr>
        <tr>
            <td>sentence_id (FK)</td>
            <td>INTEGER</td>
            <td>Sentence object primary key.</td>
        </tr>
        <tr>
            <td>sentence_sub_type</td>
            <td>INTEGER</td>
            <td>Sub type of task iteration sentence.</td>
        </tr>
        <tr>
            <td>sentence_text</td>
            <td>TEXT</td>
            <td>Text of task iteration sentence.</td>
        </tr>
        <tr>
            <td>sentence_difficulty</td>
            <td>INTEGER</td>
            <td>Difficulty level of task iteration sentence.</td>
        </tr>
        <tr>
            <td>sentence_correct_answers</td>
            <td>TEXT ARRAY</td>
            <td>Possible correct answers of task iteration sentence.</td>
        </tr>
        <tr>
            <td>sentence_error_words</td>
            <td>TEXT ARRAY</td>
            <td>Possible erroneous words for task iteration sentence.</td>
        </tr>
    </table>
    <table>
        <caption><b>Vocabulary Guessing</b></caption>
        <tr>
            <th>Name</th>
            <th>Type</th>
            <th>Description</th>
        </tr>
        <tr>
            <td>id (PK)</td>
            <td>INTEGER</td>
            <td>Primary key.</td>
        </tr>
        <tr>
            <td>student_id (FK)</td>
            <td>INTEGER</td>
            <td>Student object primary key.</td>
        </tr>
        <tr>
            <td>group_id (FK)</td>
            <td>INTEGER</td>
            <td>Group object primary key.</td>
        </tr>
        <tr>
            <td>turn_start</td>
            <td>TIMESTAMP</td>
            <td>When the task iteration started.</td>
        </tr>
        <tr>
            <td>turn_duration</td>
            <td>INTERVAL</td>
            <td>Duration of the task iteration.</td>
        </tr>
        <tr>
            <td>correct</td>
            <td>BOOLEAN</td>
            <td>If the task iteration was completed successfully.</td>
        </tr>
        <tr>
            <td>skipped</td>
            <td>BOOLEAN</td>
            <td>If the vocabulary word was skipped.</td>
        </tr>
        <tr>
            <td>messages_elected_user</td>
            <td>INTEGER</td>
            <td>Number of messages sent by elected user during the task iteration.</td>
        </tr>
        <tr>
            <td>messages_other_users</td>
            <td>INTEGER</td>
            <td>Number of messages sent by non-elected users during the task iteration.</td>
        </tr>
        <tr>
            <td>description_texts</td>
            <td>TEXT ARRAY</td>
            <td>Descriptions offered by the elected user during the task iteration/</td>
        </tr>
        <tr>
            <td>vocab_id (FK)</td>
            <td>INTEGER</td>
            <td>Vocabulary object primary key.</td>
        </tr>
        <tr>
            <td>vocab_sub_type</td>
            <td>INTEGER</td>
            <td>Sub type of task iteration vocabulary word.</td>
        </tr>
        <tr>
            <td>vocab_word</td>
            <td>TEXT</td>
            <td>Task iteration vocabulary word.</td>
        </tr>
        <tr>
            <td>vocab_difficulty</td>
            <td>INTEGER</td>
            <td>Difficulty level of task iteration vocabulary word.</td>
        </tr>
    </table>
</div>

### Closing Remarks

The aforementioned data are used primarily to inform the *path* selection module, but are also intended to permit future meta-analysis of user-item interaction and have already been applied to a testing strategy outside the scope of the documentation of this section. For further details of these evaluative applications please refer to the relevant [documentation chapter]({{ "" | absolute_url }}/#).

Of final note are the next steps potentiated by these data, as it is clear that the *path* selection module in its current form does not take full advantage of the metadata collected, and it is likely a point of future development to, following detailed analysis of the available user performance data, expand the application's intelligent adaptivity with more extensive requisition of the collected data.

