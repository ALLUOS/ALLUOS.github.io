---
layout: post
title: Adaptive Module
sections:
 - title: Overview
   tag: \#overview
 - title: Path Selection
   tag: \#path
 - title: Data Collection
   tag: \#data
---

<div id="overview"></div>
## Overview
The adaptive module is the application's component which provides individual users and, by extension, groups, with content which is attuned to their previous performance. For a detailed explanation of the basic adaptive module approach developed during the first semester of the project, please refer to the relevant chapter of the [implementation section]({{ "" | absolute_url }}/2020/05/02/implementation.html#adaptive). In this semester, we augmented the basic adaptive module by injecting user feedback and additional performance metadata. Justification and explanation of this so-called '*path* selection' module, including its supporting data sources, can be found in the following sections.

------

<div id="path"></div>
## Adaptive module weaknesses led to player self-regulation approach

### The missing scientific backing and unclear justification are the adaptive modules problems.

At the end of the last semester we conducted an [evaluation of the adaptive module's validity]({{ "" | absolute_url }}/2020/05/01/evaluation.html#usability). This evaluation concluded that the module would need further development in the second semester. The reasoning behind this conclusion was that its proficiency model relied too heavily on intuitive difficulty and the module's goal of favoring the players' weaknesses lacked justification. In summary, the problems of the module were:

1. the missing scientific backing for its positive learning impact,
2. the missing scientific backing for the item difficulty classification,
3. the missing justification for the prioritization of weak player categories,
4. the missing of data to solve the above points.

### A paradigm shift to player self-regulation neutralizes the problem.

We noticed that other self-adjusting models suffer the same justification problem because the effectiveness and justification for a self-adjusting adaptive module is too dependent on the specific circumstances of its application. This meant we either had to research our model's effectiveness ourselves or circumvent the problem otherwise.

Our solution was to accompany the self-adjusting model as it is with a model using player self-regulation to influence difficulty adaption. Now the player themselves can intervene, if the difficulty level or category prioritization are not serving their learning goals.

Despite our change of approach, we still need to prove the positive learning impact of the adaptive module. We address this need with a dedicated data collection module you can read about below and with [extensive testing]({{ "" | absolute_url }}/#).

How all of this new features interact with each other and within the adaptive module you can see in the graphic below.

<img src="{{ '' | absolute_url }}/assets/images/overview_adaptive_module.jpg" class="center">

### The *path* selection choice after each task iteration is partially data driven.

The player first interacts with the path selection module after his first task. The player is asked to choose a new *path* to influence the further tasks. For the moment the player is provided with four options:

1. increase all difficulties,
2. decrease all difficulties,
3.  focus on a single category,
4. don't select a path,

as you can see in the screen shot below. While the first two options and the fourth are still generic, we already use collected data to choose the third option. We would like to extend this data driven approach in future versions of the module.

<img src="{{ '' | absolute_url }}/assets/images/screen_1_adaptive.jpg" class="center">

### Each *path* can influence both the difficulty and the probability with which a category is chosen

Each *path* object consists out of  a `path_name`, an `path_id`, three dictionaries `prof_dict`, `prob_dict`, `conditions` and a boolean `set_prob` variable.

The `path_name` and the `path_id` are for identifying the path type.

The dictionary `prof_dict` encodes the change in proficiency the *path* is exerting.  For example the *increase all difficulties* *path* has the following dictionary: `{0.1 for all proficiencies in Vocabulary or Grammar}`. This means all proficiencies of the player are increased by 0.1 for this *path*.

The `prob_dict` dictionary encodes the change in probability the *path* is  exerting. For example the *focus on a single category* has the following dictionary: `{1 for chosen category; 0 for other categories in Vocabulary or Grammar}`. This means the only category that has any probability is the chosen one.

### The new process is kept totally compatible with the adaptive module.

When a player chooses a *path* after a task, it is registered in a `path` list object in the student object of the player.

During task item selection a category has to be selected. Either the probability to pick a certain category is completely determined by the *path*. This happens, when a *path* has the `set_prob` attribute set to `True`. If this is the case only the last *path* with that property is valid and the category is chosen according to the probabilities in his `prob_dict` dictionary. The second case is all *paths* have `set_prob = False`. Then the probabilities of a *path* are added to the existing probabilities and then these probabilities are normed. This happens in their acquisition order for all *paths*.

Second, a difficulty is selected. The players proficiency for the selected category is added to the values of each *path*.  The calculated proficiency is always kept under 10 or and over 0.  The calculated domain specific proficiency is then balanced against the more general average proficiency.

Finally, an item out of the chosen category with the calculated difficulty is randomly selected out of the database.

***

<div id="data"></div>
## Adaptive Data

To support the above-described *path* selection functionality and to select *paths* more-intelligently we needed additional user performance data.

### General Approach

As outlined in the chapters devoted to the sentence correction and vocabulary guessing tasks, both activities coordinate groups of users around a [sequentially-progressive task]({{ "" | absolute_url }}//2020/05/01/implementation.html#framework) by iterating over individual users as targeted activity leaders. In this way, each iteration is associated more-heavily with a particular user and can be inferred as more relevant to their performance for the purposes of performance data collection. Given the assumption, that each iteration can be associated directly with the elected participant, we record task iteration metadata and attribute these to the selected user as a measure of his/her success with the particular task item. For example, in a sentence correction task iteration in which one user is attempting to successfully-correct an erroneous sentence with the help of other users, the total time taken to complete the iteration is assumed to be indicative of the elected user's ability to resolve the presented sentence item and, by extension, informs suggested *paths* at the conclusion of all task iterations.

In the below section we describe how this data collection procedure can be conceptualized at a higher level relevant to the backend application infrastructure.

### Technical Infrastructure and Further Details

The below diagram summarizes the adaptive module data collection protocol as it is integrated within the sequential task flow, with task iteration performance metadata collected during each user-association iteration before being stored to the PostgreSQL database at the end of the user's turn. After all task iterations when the *path* selection options are presented, we retrieve previous user performance entries from the database and prioritize a dynamic third option based on the duration of previous task iterations associated with a specific sub-skill. In effect, that sub-skill which required the most time for a selected user to complete will determine the third option.

<img src="{{ '' | absolute_url }}/assets/images/adaptive_data_collection.png" class="center">

### Closing Remarks

The aforementioned data are used primarily to inform the *path* selection module, but are also intended to permit future meta-analysis of user-item interaction and have already been applied to a testing strategy outside the scope of the documentation of this section. For further details of these evaluative applications please refer to the relevant [documentation chapter]({{ "" | absolute_url }}/2020/04/04/testS2#methods).

Of final note are the next steps potentiated by these data, as it is clear that the *path* selection module in its current form does not take full advantage of the metadata collected, and it is likely a point of future development to, following detailed analysis of the available user performance data, expand the application's intelligent adaptivity with more extensive requisition of the collected data.

