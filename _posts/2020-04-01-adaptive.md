---
layout: post
title: Adaptive Module
---

## Overview
The adaptive module is that component of the application which provides individual users and, by extension, groups, with
content which is attuned to their previous performance. We intend to optimize application engagement by ensuring that
no task is neither too difficult nor too simple for a given user at any point in time. To achieve these goals, we associate
each task item with specific language sub-skills which, combined with user performance metadata, allow the application to more-intelligently
select future tasks. For a detailed explanation of the basic adaptive module approach developed during the first semester of the
project, please refer to the relevant chapter of the [implementation section]({{ "" | absolute_url }}/2020/05/02/implementation.html#adaptive).
In this semester, we augmented the basic adaptive module by injecting user feedback and additional performance metadata. Justification and
explanation of this so-called 'path selection' module, including its supporting data sources, can be found in the following sections.

# Path Selection Module

## Prior model lacks lead to player self-regulation approach

### The prior self-adjusting adaption model was based on layered proficiency categories

The end of our first semester saw the implementation of a difficulty adaption build upon a refined user proficiency model. In this model the task items were grouped according to their difficulty and their grammatical or lexical categories. The users also got ranked according to this categories both on the more general level (grammar/lexicality) and on the subcategory level (specific grammar/lexical themes). This ranking was used to select items of appropriate difficulty from each category prioritizing weak categories for each player.

### The missing scientific backing and unclear justification are the prior adaption models problems

Together with the proficiency model of the last semester we created an evaluation of its validity. The evaluation concluded that the model would need further development in the second semester. The reasoning behind this conclusion was the prior models reliance on intuitive measures and the lacking justification of its goals. The evaluation revealed that the proficiency modeling and the goals of an adaptive module hat to be checked against scientific evidence on the learning impact of self-adjusting difficulty models.  The problems the evaluation mentions are thus:

1. missing scientific backing for a positive learning impact,
2. missing scientific backing for the item difficulty classification,
3. no justification for the prioritization of weak player categories,
4. missing data for the evaluation of effectiveness.

### A shift to self-assessment neutralizes this problems by incorporating players self-regulation

We noticed that alternative self-adjusting models suffer the same justification problems as our old model, because the effectiveness of and justification for a self-adjusting adaption module is too dependent of the specific circumstances of its application. This meant we either had to research our models effectiveness ourselves or circumvent this problem otherwise.

Our solution was to accompany the self-adjusting model as it is with a model using player self-assessment to influence difficulty adaption. This relieved us of some of the above problems, as the player themselves can intervene, if they think difficulty level or category prioritization are not serving his learning goals. Thus the severity of inaccurate difficulty classification and improper category prioritization of the self-adjusting model is alleviated by players self-regulating behavior.

To prove the positive learning impact of the adaption module stays a goal of our team, as well as the collection of data to prove it. This need only increases with the addition of new features. Both is part of the data collection module that was also part of this semesters work.

## The new module unites a data driven approach with player self-regulation and the prior modules adaption processes

The main idea of this module is to create easy to understand *paths* that the player is able to choose from in order to make an informed decision about the further development of difficulty and prioritization during the task.

### The *path* selection choice after each task iteration is supposed to be data driven

The first interaction a player has with the path selection module is after the first task. The player is asked to choose a new *path* to influence the further development of the task after each iteration of any task. For the moment the player is provided with four options:

1. Increase all difficulties,
2. decrease all difficulties,
3. focus on a single category,
4. don't select a path.

While the first two options and the fourth are still generic we already choose the third option by identifying the task category the user took the longest to answer in the last iteration of task. We would like to extend this data driven approach in future versions of the module.

### Each path can influence both the difficulty and the probability with which every category is chosen

Each *path* consists out of  a `path_name`, an `path_id`, three dictionaries (`prof_dict`, `prob_dict`, `conditions`) and a boolean `set_prob` variable.

Clearly the `path_name` and the `path_id` are for identifying the path type.

The dictionary `prof_dict` encodes the change in proficiency the path is exerting.  For example the *increase all difficulties* path has the following dictionary: `{0.1 for all proficiencies in Vocabulary or Grammar}`. This means all proficiencies of the player are increased by 0.1 for this path.

The `prob_dict` dictionary encodes the change in probability the path is  exerting. For example the focus on a single category has the following dictionary: `{1 for chosen category 0 for other categories in Vocabulary or Grammar}`. This means the only category that has any probability is the chosen one. The `set_prob` variable handles two different methods of exerting the influence the path has on probability. Either it is set to `False` then the prioritization of the prior adaption module is left intact and only the values specified in the dictionary are changed or it is set to `True` then the prioritization of the prior adaption module is overridden and the specified values are set. All other values are equally distributed among the left over probability.

### This process is kept totally compatible with the prior adaption process

When a player chooses a path after a task it is registered in a `path` list in the student object of the player. Whenever a task item has to be chosen the priors model selection function is called (`selection.py`). If the player has *paths* in is `path` list these *paths* are used to influence the probability and the difficulty with which a category is selected.

First a category is selected. Either the probability is completely determined by the path. This happens, when a path has the `set_prob` attribute set to `True`. If this is the case only the last path with that property is valid and it dominates the probability distribution. The second case is all paths have `set_prob = False`. Then the probabilities of a path are added to the existing probabilities and then the probabilities are normed again. This happens in order of acquisition for all *paths*.

Second a difficulty is selected. The players proficiency for the selected category is added by the values of each *path*. If the proficiency exceeds 10 or drops below 0 it is kept constant. Now we proceed as in the prior model by balancing between category specific and domain average proficiency.

### The story telling integration can be can be read in the according section

Lastly the new module was provided with a story telling integration. Read more about this in the story telling section of this semester.

***

### Adaptive Data

To support the above-described path selection functionality we required additional user performance data in order to both more-intelligently suggest possible
'paths' to the users, and also to stockpile more-extensive performance data for the purposes of future item-response analysis and performance-based
user experience evaluations. Further details on the applications of these data for the semester-two user evaluations can be found in the relevant
chapter of the [Summary and Evaluation section]({{ "" | absolute_url }}/#). In the below chapters we briefly describe the data collection approach
and some applications of these data relevant to the adaptive module.

#### General Approach

Because this semester saw the introduction of an [additional task]({{ "" | absolute_url }}/#) during the development of the
path selection module, we have only implemented significant path selection support for the [sentence correction and
vocabulary guessing](additional task]({{ "" | absolute_url }}/2020/05/03/design.html#design) tasks. Given that the newly-added discussion task currently supports a less-extensive integration of the
path selection module relevant to data collection, the first two tasks will alone be the focus of this deep-dive into the
data collection.

As outlined in the relevant chapters devoted to the sentence correction and vocabulary guessing tasks respectively, both activities
coordinate groups of users around a sequentially-progressive task by iterating over individual users as targeted activity leaders.
In this way, each iteration is associated more-heavily with a particular user and can be inferred to be more relevant to his/her
performance for the purposes of performance data collection. Given this assumption that each iteration can be associated directly with
the elected participant, we record task iteration metadata and attribute these to the selected user as a measure of his/her
success with the particular task item. For example, in a sentence correction task iteration in which one user is attempting to
successfully-correct an erroneous sentence with the help of other users, the total time taken to complete the iteration is assumed to
be indicative of the elected user's ability to resolve the presented sentence item and, by extension, informs suggested paths at the
conclusion of all task iterations. In the below section we describe how this data collection procedure can be conceptualized at
a higher level relevant to the backend application infrastructure.

#### Technical Infrastructure and Further Details

The below diagram summarizes the adaptive module data collection protocol as it is integrated within the sequential task flow,
with task iteration performance metadata collected during each user-association iteration before being stored to the PostgreSQL
database at the end of the user's turn. At the end of all task iterations when the path selection options are presented, we
retrieve previous user performance entries from the database and prioritize a dynamic third option based on the duration
of previous task iterations associated with a specific sub-skill. In effect, that sub-skill which required the most time for
a selected user to complete will determine the third option.

<img src="{{ '' | absolute_url }}/assets/images/adaptive_data_collection.png" class="center">

The below tables summarize the collected adaptive data for the two tasks.

<div>
    <table>
        <caption><b>Sentence Correction</b></caption>
        <tr>
            <th>Name</th>
            <th>Type</th>
            <th>Description</th>
        </tr>
        <tr>
            <td>id (PK)</td>
            <td>INTEGER</td>
            <td>Primary key.</td>
        </tr>
        <tr>
            <td>student_id (FK)</td>
            <td>INTEGER</td>
            <td>Student object primary key.</td>
        </tr>
        <tr>
            <td>group_id (FK)</td>
            <td>INTEGER</td>
            <td>Group object primary key.</td>
        </tr>
        <tr>
            <td>turn_start</td>
            <td>TIMESTAMP</td>
            <td>When the task iteration started.</td>
        </tr>
        <tr>
            <td>turn_duration</td>
            <td>INTERVAL</td>
            <td>Duration of the task iteration.</td>
        </tr>
        <tr>
            <td>performance</td>
            <td>INTEGER</td>
            <td>Number of task iteration phases successfully passed.</td>
        </tr>
        <tr>
            <td>messages_elected_user</td>
            <td>INTEGER</td>
            <td>Number of messages sent by elected user during the task iteration.</td>
        </tr>
        <tr>
            <td>messages_other_users</td>
            <td>INTEGER</td>
            <td>Number of messages sent by non-elected users during the task iteration.</td>
        </tr>
        <tr>
            <td>sentence_id (FK)</td>
            <td>INTEGER</td>
            <td>Sentence object primary key.</td>
        </tr>
        <tr>
            <td>sentence_sub_type</td>
            <td>INTEGER</td>
            <td>Sub type of task iteration sentence.</td>
        </tr>
        <tr>
            <td>sentence_text</td>
            <td>TEXT</td>
            <td>Text of task iteration sentence.</td>
        </tr>
        <tr>
            <td>sentence_difficulty</td>
            <td>INTEGER</td>
            <td>Difficulty level of task iteration sentence.</td>
        </tr>
        <tr>
            <td>sentence_correct_answers</td>
            <td>TEXT ARRAY</td>
            <td>Possible correct answers of task iteration sentence.</td>
        </tr>
        <tr>
            <td>sentence_error_words</td>
            <td>TEXT ARRAY</td>
            <td>Possible erroneous words for task iteration sentence.</td>
        </tr>
    </table>
    <table>
        <caption><b>Vocabulary Guessing</b></caption>
        <tr>
            <th>Name</th>
            <th>Type</th>
            <th>Description</th>
        </tr>
        <tr>
            <td>id (PK)</td>
            <td>INTEGER</td>
            <td>Primary key.</td>
        </tr>
        <tr>
            <td>student_id (FK)</td>
            <td>INTEGER</td>
            <td>Student object primary key.</td>
        </tr>
        <tr>
            <td>group_id (FK)</td>
            <td>INTEGER</td>
            <td>Group object primary key.</td>
        </tr>
        <tr>
            <td>turn_start</td>
            <td>TIMESTAMP</td>
            <td>When the task iteration started.</td>
        </tr>
        <tr>
            <td>turn_duration</td>
            <td>INTERVAL</td>
            <td>Duration of the task iteration.</td>
        </tr>
        <tr>
            <td>correct</td>
            <td>BOOLEAN</td>
            <td>If the task iteration was completed successfully.</td>
        </tr>
        <tr>
            <td>skipped</td>
            <td>BOOLEAN</td>
            <td>If the vocabulary word was skipped.</td>
        </tr>
        <tr>
            <td>messages_elected_user</td>
            <td>INTEGER</td>
            <td>Number of messages sent by elected user during the task iteration.</td>
        </tr>
        <tr>
            <td>messages_other_users</td>
            <td>INTEGER</td>
            <td>Number of messages sent by non-elected users during the task iteration.</td>
        </tr>
        <tr>
            <td>description_texts</td>
            <td>TEXT ARRAY</td>
            <td>Descriptions offered by the elected user during the task iteration/</td>
        </tr>
        <tr>
            <td>vocab_id (FK)</td>
            <td>INTEGER</td>
            <td>Vocabulary object primary key.</td>
        </tr>
        <tr>
            <td>vocab_sub_type</td>
            <td>INTEGER</td>
            <td>Sub type of task iteration vocabulary word.</td>
        </tr>
        <tr>
            <td>vocab_word</td>
            <td>TEXT</td>
            <td>Task iteration vocabulary word.</td>
        </tr>
        <tr>
            <td>vocab_difficulty</td>
            <td>INTEGER</td>
            <td>Difficulty level of task iteration vocabulary word.</td>
        </tr>
    </table>
</div>

#### Closing Remarks

As mentioned, the aforementioned data are used primarily to inform the path selection module, but are also intended to permit
future meta-analysis of user-item interaction and have already been applied to a testing strategy outside the scope of the
documentation of this section. For further details of these evaluative applications please refer to the relevant
[documentation chapter](additional task]({{ "" | absolute_url }}/#). Of final note are the next steps potentiated by these data, as it
is clear that the path selection module in its current form does not take full advantage of the metadata collected, and it is likely
a point of future development to, following detailed analysis of the available user performance data, expand the application's
intelligent adaptivity with more extensive requisition of the collected data.

