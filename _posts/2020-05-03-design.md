---
layout: post
title: Design
description: Under construction!
image: pic02.jpg
---

Problem description:
- target group
- learning scenario
- results from market research?

Design process:
- interaction design, general cooperative set-up
- describe the two task in detail
- problems we faced

 
### Task 2 Design Process

For Task 2, the goal was to come up with an activity that, just like Task 1, gives users a chance to interact with one another. The other goal was to help users in another aspect of language learning than Task 1. In Task 1, users focus on grammatical error detection, and in Task 2, they are supposed to work on vocabulary learning. 
For that, a word guessing task is designed in which each user is given a word within a certain difficulty level, and he/she is supposed to describe it and what it means to the other people in the group in order for them to guess the word. In case the person whose turn is up doesn’t know the meaning of the word given to him/her, there is an option to choose an alternate word. And in case each user successfully describes the word and other users guess it correctly, one round of the game is over, and according to the narration of the game, they unlock one part of the passcode to exit the escape room.
Finally, the task is timed so that participants do not have the chance to cheat (check the definition of the words outside of the game), and the pace is fast enough to keep the game exciting.
For this task, the Design team had to create a dataset of words that are appropriate for CEFR Level B1 English learners. These words were extracted from Cambridgeenglish.org that were divided according to their relevant topics into 11 subcategories. These topics were then translated into seven subskills obtained from Wordnet (Free_time, Humanities, Society, Nature and science, Ailment, Body and soul, and Home and building).
The next challenge was to categorize these words according to their difficulty level, which was not given in the dataset as in Task 1. Group 2, therefore, had to come up with features that helped them in determining word difficulty. A standard indicator of word difficulty is word length – short words tend to be easier to read. This feature could be easily computed by only relying on the list of words. However, the resulting categories that solely were divided according to this feature had many incorrectly categorized words. Another feature that was helpful in measuring word difficulty was the number of word senses (Medero, & Ostendorf, 2009). This could not be inferred from the list of words alone and required an extra resource for which we used Wordnet. We extracted the number of senses each word had in Wordnet. This feature was negatively correlated with word difficulty (the more meanings a word has, the easier it usually is). However, this feature also had exceptions and in and of itself, was not sufficient to measure word difficulty. 
The most prominent feature that was used in different studies to estimate word difficulty was word frequency (Chen & Detmar 2016; Rudell, 1993). This, by far, was the most difficult feature to extract as well because it required a large enough and widespread - among different topics - corpus to show a reliable result for word frequency within a language. For that, we used SUBTLEX US corpus and measured word frequency based on that. This feature was also negatively correlated with word difficulty. 
With these three metrics, we now had to find a way to calculate word difficulty accordingly. Since the importance of each of these features in estimating word difficulty were not equal, we needed to find out to what extent each metric contributes to word difficulty. For that, these metrics needed to have non-equal weights for making a final unified measure for word difficulty. However, we didn’t know what weight to give to each of them. 
To find their weights, we created a hand-labeled small training set of these words chosen randomly to run a neural network over and find the proper weights for each of the above-mentioned features. As we expected, the highest weight was for word frequency, the second weight was for word length, and the least contributing feature to difficulty estimation was the number of senses. In the next step, we normalized all three of these features’ original values and then computed the sum of the weighted values (subtracting for the negatively correlated features). The resulting weighted sum became our final metric for word difficulty. We sorted the words according to this metric, and based on the three-level difficulty that we had in Task 1, we divided this sorted list into three difficulty levels.
Of course, we should keep in mind that this difficulty estimation does not result in 100% accurate categorization. One prominent counterexample is the word “businesswoman” that is low in frequency and is a rather long word, has only one entry in Wordnet, and according to all these measurements, it should be categorized as a difficult word (difficulty level 3). However, it is actually a rather easy word. This indicates that there is room for improvement, and semantic features of words (like difficulty) are not easily quantifiable by word’s formal features.

#### References:
Chen, Xiaobin & Meurers, Detmar. (2016). Characterizing Text Difficulty with Word Frequencies. 84-94. 10.18653/v1/W16-0509. 
Rudell, A. P. (1993). Frequency of word usage and perceived word difficulty: Ratings of Kučera and Francis words. Behavior Research Methods, Instruments & Computers, 25(4), 455–463. https://doi.org/10.3758/BF03204543
Medero, Julie & Ostendorf, Mari. (2009). Analysis of vocabulary difficulty using Wiktionary. SLaTE: 61-64



### Summary of functional requirements
In summary, the chat bot should provide functionality for a group interaction in which 15 to 16 year old students (language level B1) can train their communication skills in the English language outside of a school setting. This requires that users can form and/ or join groups of up to four members when using the application. Generally, the chat bot should in its interaction with the users use language and task descriptions that match the B1 language level of the target group. Additionally, gamefication is included in the design of the application. The chat bot needs to track users' progress in solving the tasks and provide them with clear feedback and rewards when tasks are successfully completed to further motivate and engage them. Once the group has been formed the application needs to allow users to chose one of the two developed tasks.

Detailed functional requirements follow from the in-depth description of the two developed tasks provided above. For both tasks it is necessary that each user is chosen in turn as the main active user, who either attempts to correct the sentence (task one) or provides a description for the current word (task two). This means that the application needs to track which users have already performed the task in any given round and select a new user for each turn. The application should model users' skill level for relevant language components: vocabulary (trained through task two) and grammar (trained through task one). Each of these broad language components is represented through a set of specific sub-skills. Performing the tasks should train some of these sub-skills and the application needs to monitor individual and group level skills to adequately chose a task difficulty. Additionally, each task has specific functional requirements necessary to provide an adequate user experience.

For task one the chat bot should guide users through the individual parts of the task (identifying error and correcting it) to ensure that users understand what is expected of them. Once a user attempts to solve a part of the task the application should provide immediate feedback and if necessary corrections so that the user can learn the correct solution to the task.

The second task requires that the bot chooses a new word from the list of available words which the active user should explain in the chat. If a user is tasked with explaining a word they do not know they need the option to chose a different word. This means that in providing a word to explain to a user the application additionally should provide the option to reject this word. The application should detect the use of the to-be-explained word in the chat by the user who is supposed to explain it in order to prevent this basic form of cheating in the task. The bot should in such a case mark the task as incorrectly answered. In case one of the other users correctly guesses the word the application needs to detect the solution in the chat and mark the round in the task as solved.
