---
layout: post
title: Design
description: Under construction!
image: pic02.jpg
---

## Problem description

### Target group

The target group that we considered that fit the best for the goal of this application comprises non-native english learners. In particular, high school students who already have an upper-intermediate level of language proficiency and are about 15 years old. We took the English learning competency level as our measurement of proficiency, as defined by the Common European Framework of Reference for Languages (CEFR). We then designed our application for learners with a proficiency around the B1-B2 level. While B1 refers to an intermediate or ‘threshold’ level of language, B2 refers to an upper-intermediate level (CEFR, 2020).

After reaching the B1 Level, students are able to express und understand English sufficiently for basic interactions in a more informal environment. They are also able to produce simple, short texts about topics in which they feel familiar and confident and to communicate with native speakers in these topics. Therefore, one can say that students of the level B1 are able to engage and solve problems in everyday life situations (CEFR, 2020). However, B1 is not sufficient to complete, for instance, a course of study or to work in an english speaking environment. English learners at level B2, on the other hand, have more advanced skills in comparison to those on a B1 level. They are able to understand the main topics of complex texts and to interact in a more flexible way, also concerning topics which are not familiar to them (CEFR, 2020). 

Therefore, we expect that the target users are able to understand questions and the explanations concerning tasks and to communicate on a basic to advanced level. It is also important to note that our target group focusses on high school students at the age of 15. Thus, we are taking into consideration that they are likely to accustom to the use of smartphones and instant message applications, such as telegram. As they are also receiving instructions in English at school, this application focusses on the practice and training of already existing language skills. 

### References 

- CEFR (Common European Framework for Reference of Language) 2020, Global scale - Table 1 (CEFR 3.3): Common Reference levels. https://www.coe.int/en/web/common-european-framework-reference-languages/table-1-cefr-3.3-common-reference-levels-global-scale

### Learning Scenario

To make the users learn English effectively, we designed the tasks using two main scenarios; a group scenario and a narrative scenario. A group setting provides users the environment of cooperative learning (or collaborative learning). Cooperative learning refers to a particular set of classroom techniques that encourage learner interdependence as a route to cognitive and social development (Johnson 1991). In this environment, since users with a higher level of and lower level randomly mixed, users have opportunities to act as resources for others and suppose a more active role in learning (Mary 1989). Those who have a higher level could learn by teaching others. For example, in task 2 where one person has to explain about a given word to the others in the group, users should try to describe the word even though they already get used to it. In the process, users need to recall the definition, consider a situation where those words would be used, and ensure their understanding of English. On the other hand, those how have a lower level could improve their English by practicing in various random conversational situations.  

In this cooperative learning situation, users will be given a common goal and work together to get the goal. In the meantime, users will be able to support each other and get social interaction which is not a common function other language learning applications provide. According to research at Sakarya University (Bahrani & Sim 2012), social interaction is a crucial source of language learning which can occur outside of the classroom setting. Furthermore, by cooperating together, users could feel to be engaged with each other. As Astin said, the best learning environment for higher education is one in which it is possible to increase engagement (Astin 1984).

The second method we used to make users learn a language effectively is a narrative scenario, especially an escape scenario where users are supposed to be abducted by Alien and escape by solving a few tasks together. Considering the age of our target group who can easily lose their concentration, we expected this gamification of education will help users keep interested and lessen stresses for language learning. Applying gamification in education as learning tools is a promising approach since they strengthen important skills such as problem-solving, collaboration, and communication as well as knowledge (Dicheva, Darina, et al 2015).

Moreover, given a reward, a hint of a key, of completing each task successfully, users continuously being engaged and motivated. It is largely agreed that reward is an important role in terms of creating motivation (Baranek 1996). Each time users obtain a hint of the key, they could picture where they at in the whole story and be prompted to solve further tasks to collect remaining hints. 

#### References
- Johnson, D. W. (1991). Cooperative Learning: Increasing College Faculty Instructional Productivity. ASHE-ERIC Higher Education Report No. 4, 1991. ASHE-ERIC Higher Education Reports, George Washington University, One Dupont Circle, Suite 630, Washington, DC 20036-1183.
- Mary McGroarty (1989) The Benefits of Cooperative Learning Arrangements in Second Language Instruction, NABE Journal, 13:2, 127-143, DOI: 10.1080/08855072.1989.10668555
- Bahrani, T., & Sim, T. S. (2012). Informal Language Learning Setting: Technology or Social Interaction?. Turkish Online Journal of Educational Technology-TOJET, 11(2), 142-149.
- Astin, A. W. (1984). Student involvement: A developmental theory for higher education. Journal of college student personnel, 25(4), 297-308.
- Dicheva, D., Dichev, C., Agre, G., & Angelova, G. (2015). Gamification in education: A systematic mapping study. Journal of Educational Technology & Society, 18(3).
- Baranek, L. K. (1996). The effect of rewards and motivation on student achievement.


### Results from the Market Research

In the mentioned market research we examined already existing applications for language learning, specifically for the learning of English. Since the goal of this project is the development of a language learning application supported by methods of Artificial Intelligence (AI), more specifically, Adaptive Language Learning (ALL), we were even more interested in the use of AI and ALL tools in those applications.

According to our market research, the most important gap is to be found in applications that focus on group learning scenarios. Specifically, on learning environments, in which one is fully dependent on the other group members to fulfill a task. This is interesting as learning in groups, also described as cooperative learning, can have positive influences on learning languages (Zhang, 2010). We also found that, so far, there is no application using an environment that relies entirely on conversational learning and not only e.g. a click-a-button method. While there are applications that used methods of machine learning and conversational agents, we did not find any that also relied on group learning. Furthermore, we also did not find group learning environments that support conversations and communication among learners or between learners and a bot. 

This concluded that for our application it is important to design tasks that, on the one hand, use the benefits from group learning and, on the other hand, enforce a natural communication to practice those skills for the learners. To foster the group learning scenario and give the learners an opportunity to benefit thereof, it is important that we create tasks where they have to engage with each other and rather than merely working on their own. The possibility for cheating behavior should also be minimized. To create the opportunity for the learners to practice natural communication, the task coordination is performed by the bot through a conversation with the learners. This communication should look as natural as possible to the students. Moreover, It is also important to support constant communication between the bot and the learner and with other learners.

Gamification, as also seen in many other applications, is an important part of successfully learning a second language, outside a ‘classic’ learning environment (Flores, 2015). Gamification describes the inclusion of aspects of games into a non-game environment (Flores, 2015). To enhance the motivation of our users, our tasks should be integrated into a more complex framework and should work in a game-like scenario. 

Altogether, our target group corresponds to students who already posses an intermediate proficiency in english. The application should focus on the practicing of language skills, while supporting the students in a natural communication with each other and the bot. 


### References 

- Flores, J. F. F. (2015). Using gamification to enhance second language learning. Digital Education Review, (27), 32-54.
- Zhang, Y. (2010). Cooperative language learning and foreign language learning and teaching. Journal of Language Teaching and Research, 1(1), 81-83.

Design process:
- interaction design, general cooperative set-up
- describe the two task in detail
- problems we faced

## Design Process

### Task 1 - Design Process
The aim for the first task of the study project was to create an exercise which combined discussing and working together in a group of users with revising linguistic structures in English for learners at an intermediate language level. Once again it should be highlighted that the application is targeted on the need for learners to supplement the English lessons they get in school and not to give concrete instructions and new lessons about certain topics.

So, task 1 was decided to be a sentence error correction task. In this rather technical task, one user is chosen by the bot to take a turn, which concentrates on one sentence, displayed in the chat for all users. The turn consists of firstly deciding whether the sentence is correct or incorrect and secondly, in the case of an incorrect sentence, picking the incorrect word and providing the correct alternative for it. 

The idea of this type of a primarily grammar-focused task was developed out of the wish for a task which concentrates on sentence construction. As the principle of error correction by the teacher in language learning is controversially discussed (Pawlak 2014, p. 149) but a proficient learner should be able to distinguish between correct and incorrect sentences, for example while revising their own texts, we decided to integrate a form of peer-correction with the last responsibility nevertheless in one user. So, the cooperative set-up in this task is introduced by giving the group of users the opportunity to discuss their thoughts on the given sentence and possible errors and asking questions in case of difficulties while completing the task. (screenshot?) 

Peer-correction “actively involves learners in the learning and teaching process” (Balderas et al. 2018, p. 184) and has been shown to be an effective method for the improvement of a learner’s writing skills (Balderas et al. 2018, p. 184). This is what we also hope to achieve with the first task which should provide a space for discussion about the sentences in question. However, the responsibility for giving an answer was decided to be given to one user on the one hand for reasons of better coordination and avoiding chaos and on the other hand to make sure to include each user in the exercise.

Only the last instance to supervise is the bot, which corresponds to the belief in learners of the greater value of teacher feedback (Pawlak 2014, p. 149) and should give the final result and confirmation. This kind of monitoring the results of the users – who are after one successful round rewarded with a letter of a password to get to the next room – should frame the interaction in the chat and encourage all users to learn from it. In addition to this, the positive feedback for successfully completed turns should work as positive reinforcement for each user.

Another point to notice about task 1 is the fact that it does not contain any explicit naming of grammar structures. The idea behind this is the training through the input of English sentences which can be seen at the edge of the use of automated explicit knowledge and implicit knowledge, pointed out by Ellis et al. (Ellis 2009, p. 342). As mentioned, it should supplement English lessons in the classroom and be a practice to strengthen the English skills.

For the concrete construction of the task, a corpus of sentences served as a source. The SCoRE Corpus of Remedial English provided sentences that are written by native English speakers, additionally annotated with grammatical categories and three difficulty levels (Chujo et al. 2015). Although this corpus does not contain errors, we chose it because it came closest to fitting our needs. We then subtracted often used sentence structures from the corpus and included them into our task to make it possible for the users to learn from example sentences by native speakers. In this way, one can understand the task as well as providing input in the target language and presenting a certain pattern that learners can pick up for their own use and understanding. The grammatical categories we chose for this purpose were adverbs, gerunds, negation, present perfect, relative clauses, subjunctive, to-infinitive, verb + preposition and verb + to-infintive.

The construction of the errors per grammatical category was then achieved by replacing the words in question in the sentence structures by alternative words which would make the sentence wrong but still point out a specific structure when corrected. One example for this would be “*She never stopped love him”, instead of loving. 

For the difficulty levels of the application’s adaptive difficulty model, we simply used the predefined levels from the SCoRE corpus, while making sure that the level is appropriate for our target users by checking random sample sentences. We decided to annotate the difficulty measure of this task with “grammar”, as the focus is on sentence structures. Of course, on cannot separate the somewhat artificial grammar-category of our difficulty model from “vocabulary”, which could also be learned and revised in this task.

The narrative to introduce users to the setting of the application and to task 1 in a following step is a science fiction story taking place in space. The users are kidnapped by an alien and try to escape from the space ship they are currently kept in. This kind of narrative and escape scenario combined with the group setting should serve as a motivation in the sense of cooperative learning: Achieving a common goal, creating positive interdependence, being able to support each other and facing a common threat are factors that should contribute to a positive learning process (Dörnyei et al. 1999, pp. 164-165).
(...)

#### References
- Balderas, I. and Guillén Cuamatzi, P. (2018). Self and Peer Correction to Improve College Students’ Writing Skills. In Profile: Issues Teachers’ Professional Development 20(2) (pp. 179-194). https://doi.org/10.15446/profile.v20n2.67095
- Chujo, K., Oghigian, K. and Akasegawa, S. (2015). A corpus and grammatical browsing system for remedial EFL learners. In A. Leńko-Szymańska and A. Boulton (eds.), Multiple Affordances of Language Corpora for Data-driven Learning (pp. 109-128). Amsterdam: John Benjamins.
- Dörnyei, Z. and Malderez, A. (1999). The role of group dynamics in foreign language learning and teaching. In J. Arnold (ed.). Affect in Language Teaching. Cambridge University Press (pp. 155-169).
- Ellis, R. et al. (2009). Implicit and Explicit Knowledge inSecond Language Learning, Testing and Teaching. Bristol: Multilingual Matters.
- Pawlak, M. (2014). Error Correction in the Foreign Language Classroom. Reconsidering the Issues. Springer-Verlag Berlin Heidelberg.

 
### Task 2 Design Process

For Task 2, the goal was to come up with an activity that, just like Task 1, gives users a chance to interact with one another. The other goal was to help users in another aspect of language learning than Task 1. In Task 1, users focus on grammatical error detection, and in Task 2, they are supposed to work on vocabulary learning. 

For that, a word guessing task is designed in which each user is given a word within a certain difficulty level, and he/she is supposed to describe it and what it means to the other people in the group in order for them to guess the word. In case the person whose turn is up doesn’t know the meaning of the word given to him/her, there is an option to choose an alternate word. And in case each user successfully describes the word and other users guess it correctly, one round of the game is over, and according to the narration of the game, they unlock one part of the passcode to exit the escape room.

Finally, the task is timed so that participants do not have the chance to cheat (check the definition of the words outside of the game), and the pace is fast enough to keep the game exciting.

For this task, the Design team had to create a dataset of words that are appropriate for CEFR Level B1 English learners. These words were extracted from Cambridgeenglish.org that were divided according to their relevant topics into 11 subcategories. These topics were then translated into seven subskills obtained from Wordnet (Free_time, Humanities, Society, Nature and science, Ailment, Body and soul, and Home and building).

The next challenge was to categorize these words according to their difficulty level, which was not given in the dataset as in Task 1. Group 2, therefore, had to come up with features that helped them in determining word difficulty. A standard indicator of word difficulty is word length – short words tend to be easier to read. This feature could be easily computed by only relying on the list of words. However, the resulting categories that solely were divided according to this feature had many incorrectly categorized words. 

Another feature that was helpful in measuring word difficulty was the number of word senses (Medero, & Ostendorf, 2009). This could not be inferred from the list of words alone and required an extra resource for which we used Wordnet. We extracted the number of senses each word had in Wordnet. This feature was negatively correlated with word difficulty (the more meanings a word has, the easier it usually is). However, this feature also had exceptions and in and of itself, was not sufficient to measure word difficulty. 

The most prominent feature that was used in different studies to estimate word difficulty was word frequency (Chen & Detmar 2016; Rudell, 1993). This, by far, was the most difficult feature to extract as well because it required a large enough and widespread - among different topics - corpus to show a reliable result for word frequency within a language. For that, we used SUBTLEX US corpus and measured word frequency based on that. This feature was also negatively correlated with word difficulty. 

With these three metrics, we now had to find a way to calculate word difficulty accordingly. Since the importance of each of these features in estimating word difficulty were not equal, we needed to find out to what extent each metric contributes to word difficulty. For that, these metrics needed to have non-equal weights for making a final unified measure for word difficulty. However, we didn’t know what weight to give to each of them. 

To find their weights, we created a hand-labeled small training set of these words chosen randomly to run a neural network over and find the proper weights for each of the above-mentioned features. As we expected, the highest weight was for word frequency, the second weight was for word length, and the least contributing feature to difficulty estimation was the number of senses. In the next step, we normalized all three of these features’ original values and then computed the sum of the weighted values (subtracting for the negatively correlated features). The resulting weighted sum became our final metric for word difficulty. We sorted the words according to this metric, and based on the three-level difficulty that we had in Task 1, we divided this sorted list into three difficulty levels.

Of course, we should keep in mind that this difficulty estimation does not result in 100% accurate categorization. One prominent counterexample is the word “businesswoman” that is low in frequency and is a rather long word, has only one entry in Wordnet, and according to all these measurements, it should be categorized as a difficult word (difficulty level 3). However, it is actually a rather easy word. This indicates that there is room for improvement, and semantic features of words (like difficulty) are not easily quantifiable by word’s formal features.

#### References:
- Chen, Xiaobin & Meurers, Detmar. (2016). Characterizing Text Difficulty with Word Frequencies. 84-94. 10.18653/v1/W16-0509. 
- Rudell, A. P. (1993). Frequency of word usage and perceived word difficulty: Ratings of Kučera and Francis words. Behavior Research Methods, Instruments & Computers, 25(4), 455–   463. https://doi.org/10.3758/BF03204543
- Medero, Julie & Ostendorf, Mari. (2009). Analysis of vocabulary difficulty using Wiktionary. SLaTE: 61-64



### Summary of functional requirements
In summary, the chat bot should provide functionality for a group interaction in which 15 to 16 year old students (language level B1) can train their communication skills in the English language outside of a school setting. This requires that users can form and/ or join groups of up to four members when using the application. Generally, the chat bot should in its interaction with the users use language and task descriptions that match the B1 language level of the target group. Additionally, gamefication is included in the design of the application. The chat bot needs to track users' progress in solving the tasks and provide them with clear feedback and rewards when tasks are successfully completed to further motivate and engage them. Once the group has been formed the application needs to allow users to chose one of the two developed tasks.

Detailed functional requirements follow from the in-depth description of the two developed tasks provided above. For both tasks it is necessary that each user is chosen in turn as the main active user, who either attempts to correct the sentence (task one) or provides a description for the current word (task two). This means that the application needs to track which users have already performed the task in any given round and select a new user for each turn. The application should model users' skill level for relevant language components: vocabulary (trained through task two) and grammar (trained through task one). Each of these broad language components is represented through a set of specific sub-skills. Performing the tasks should train some of these sub-skills and the application needs to monitor individual and group level skills to adequately chose a task difficulty. Additionally, each task has specific functional requirements necessary to provide an adequate user experience.

For task one the chat bot should guide users through the individual parts of the task (identifying error and correcting it) to ensure that users understand what is expected of them. Once a user attempts to solve a part of the task the application should provide immediate feedback and if necessary corrections so that the user can learn the correct solution to the task.

The second task requires that the bot chooses a new word from the list of available words which the active user should explain in the chat. If a user is tasked with explaining a word they do not know they need the option to chose a different word. This means that in providing a word to explain to a user the application additionally should provide the option to reject this word. The application should detect the use of the to-be-explained word in the chat by the user who is supposed to explain it in order to prevent this basic form of cheating in the task. The bot should in such a case mark the task as incorrectly answered. In case one of the other users correctly guesses the word the application needs to detect the solution in the chat and mark the round in the task as solved.
