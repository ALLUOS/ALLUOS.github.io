---
layout: post
title: Design
description: Under construction!
image: pic02.jpg
---

Problem description:

Target group

The target group that we considered that fit the best for the goal of this application comprises non-native english learners. In particular, high school students who already have an upper-intermediate level of language proficiency and are about 15 years old. We took the English learning competency level as our measurement of proficiency, as defined by the Common European Framework of Reference for Languages (CEFR). We then designed our application for learners with a proficiency around the B1-B2 level (CEFR). While B1 refers to an intermediate or ‘threshold’ level of language, B2 refers to an upper-intermediate level.

After reaching the B1 Level, students are able to express und understand English sufficiently for basic interactions in a more informal environment. They are also able to produce simple, short texts about topics in which they feel familiar and confident and to communicate with native speakers in these topics. Therefore, one can say that students of the level B1 are able to engage and solve problems in everyday life situations. However, B1 is not sufficient to complete, for instance, a course of study or to work in an english speaking environment. English learners at level B2, on the other hand, have more advanced skills in comparison to those on a B1 level. They are able to understand the main topics of complex texts and to interact in a more flexible way, also concerning topics which are not familiar to them. 

Therefore, we expect that the target users are able to understand questions and the explanations concerning tasks and to communicate on a basic to advanced level. It is also important to note that our target group focusses on high school students at the age of 15. Thus, we are taking into consideration that they are likely to accustom to the use of smartphones and instant message applications, such as telegram. As they are also receiving instructions in English at school, this application focusses on the practice and training of already existing language skills. 


- learning scenario


results from market research

In the mentioned market research we already examined existing applications for language learning, specifically for the learning of English. Since the goal of this project is the development of a language learning application supported by methods of Artificial Intelligence (AI), more specifically, Adaptive Language Learning (ALL), we were even more interested in the use of AI and ALL tools in those applications. 

According to our market research, the most important gap is to be found in applications that focus on group learning scenarios. Specifically, on learning environments, in which one is fully dependent on the other group members to fulfill a task. We also found that, so far, there is no application using an environment that relies entirely on conversational learning and not only e.g. a click-a-button method. While there are applications that used methods of machine learning and conversational agents, we did not find any that also relied on group learning. Furthermore, we also did not find group learning environments that support conversations and communication among learners or between learners and a bot. 

The concluded that for our application it is important to design tasks that, on the one hand, use the benefits from group learning and, on the other hand, enforce a natural communication to practice those skills for the learners. To foster the group learning scenario and give the learners an opportunity to benefit thereof, it is important that we create tasks where they have to engage with each other and rather than merely working on their own. The possibility for cheating behavior should also be minimized. To create the opportunity for the learners to practice natural communication, the task coordination is performed by the bot through a conversation with the learners. This communication should look as natural as possible to the students. Moreover, It is also important to support constant communication between the bot and the learner and with other learners.

Gamification, as seen in many other applications, is an important part of successfully learning outside a ‘classic’ learning environment. Gamification describes the inclusion of aspects of games into a non-ludic environment. To enhance the motivation of our users, our tasks should be integrated into a more complex framework and should work in a game-like scenario. For achieving this integration into a more complex framework, we used the scenario of an escape room. This way we could include multiple tasks into one consistent story line. 

Altogether, our target group corresponds to students who already posses an intermediate proficiency in english. The application should focus on the practicing of language skills, while supporting the students in a natural communication with each other and the bot. 

Design process:
- interaction design, general cooperative set-up
- describe the two task in detail
- problems we faced

 
### Task 2 Design Process

For Task 2, the goal was to come up with an activity that, just like Task 1, gives users a chance to interact with one another. The other goal was to help users in another aspect of language learning than Task 1. In Task 1, users focus on grammatical error detection, and in Task 2, they are supposed to work on vocabulary learning. 

For that, a word guessing task is designed in which each user is given a word within a certain difficulty level, and he/she is supposed to describe it and what it means to the other people in the group in order for them to guess the word. In case the person whose turn is up doesn’t know the meaning of the word given to him/her, there is an option to choose an alternate word. And in case each user successfully describes the word and other users guess it correctly, one round of the game is over, and according to the narration of the game, they unlock one part of the passcode to exit the escape room.

Finally, the task is timed so that participants do not have the chance to cheat (check the definition of the words outside of the game), and the pace is fast enough to keep the game exciting.

For this task, the Design team had to create a dataset of words that are appropriate for CEFR Level B1 English learners. These words were extracted from Cambridgeenglish.org that were divided according to their relevant topics into 11 subcategories. These topics were then translated into seven subskills obtained from Wordnet (Free_time, Humanities, Society, Nature and science, Ailment, Body and soul, and Home and building).

The next challenge was to categorize these words according to their difficulty level, which was not given in the dataset as in Task 1. Group 2, therefore, had to come up with features that helped them in determining word difficulty. A standard indicator of word difficulty is word length – short words tend to be easier to read. This feature could be easily computed by only relying on the list of words. However, the resulting categories that solely were divided according to this feature had many incorrectly categorized words. 

Another feature that was helpful in measuring word difficulty was the number of word senses (Medero, & Ostendorf, 2009). This could not be inferred from the list of words alone and required an extra resource for which we used Wordnet. We extracted the number of senses each word had in Wordnet. This feature was negatively correlated with word difficulty (the more meanings a word has, the easier it usually is). However, this feature also had exceptions and in and of itself, was not sufficient to measure word difficulty. 

The most prominent feature that was used in different studies to estimate word difficulty was word frequency (Chen & Detmar 2016; Rudell, 1993). This, by far, was the most difficult feature to extract as well because it required a large enough and widespread - among different topics - corpus to show a reliable result for word frequency within a language. For that, we used SUBTLEX US corpus and measured word frequency based on that. This feature was also negatively correlated with word difficulty. 

With these three metrics, we now had to find a way to calculate word difficulty accordingly. Since the importance of each of these features in estimating word difficulty were not equal, we needed to find out to what extent each metric contributes to word difficulty. For that, these metrics needed to have non-equal weights for making a final unified measure for word difficulty. However, we didn’t know what weight to give to each of them. 

To find their weights, we created a hand-labeled small training set of these words chosen randomly to run a neural network over and find the proper weights for each of the above-mentioned features. As we expected, the highest weight was for word frequency, the second weight was for word length, and the least contributing feature to difficulty estimation was the number of senses. In the next step, we normalized all three of these features’ original values and then computed the sum of the weighted values (subtracting for the negatively correlated features). The resulting weighted sum became our final metric for word difficulty. We sorted the words according to this metric, and based on the three-level difficulty that we had in Task 1, we divided this sorted list into three difficulty levels.

Of course, we should keep in mind that this difficulty estimation does not result in 100% accurate categorization. One prominent counterexample is the word “businesswoman” that is low in frequency and is a rather long word, has only one entry in Wordnet, and according to all these measurements, it should be categorized as a difficult word (difficulty level 3). However, it is actually a rather easy word. This indicates that there is room for improvement, and semantic features of words (like difficulty) are not easily quantifiable by word’s formal features.

#### References:
- Chen, Xiaobin & Meurers, Detmar. (2016). Characterizing Text Difficulty with Word Frequencies. 84-94. 10.18653/v1/W16-0509. 
- Rudell, A. P. (1993). Frequency of word usage and perceived word difficulty: Ratings of Kučera and Francis words. Behavior Research Methods, Instruments & Computers, 25(4), 455–   463. https://doi.org/10.3758/BF03204543
- Medero, Julie & Ostendorf, Mari. (2009). Analysis of vocabulary difficulty using Wiktionary. SLaTE: 61-64



### Summary of functional requirements
In summary, the chat bot should provide functionality for a group interaction in which 15 to 16 year old students (language level B1) can train their communication skills in the English language outside of a school setting. This requires that users can form and/ or join groups of up to four members when using the application. Generally, the chat bot should in its interaction with the users use language and task descriptions that match the B1 language level of the target group. Additionally, gamefication is included in the design of the application. The chat bot needs to track users' progress in solving the tasks and provide them with clear feedback and rewards when tasks are successfully completed to further motivate and engage them. Once the group has been formed the application needs to allow users to chose one of the two developed tasks.

Detailed functional requirements follow from the in-depth description of the two developed tasks provided above. For both tasks it is necessary that each user is chosen in turn as the main active user, who either attempts to correct the sentence (task one) or provides a description for the current word (task two). This means that the application needs to track which users have already performed the task in any given round and select a new user for each turn. The application should model users' skill level for relevant language components: vocabulary (trained through task two) and grammar (trained through task one). Each of these broad language components is represented through a set of specific sub-skills. Performing the tasks should train some of these sub-skills and the application needs to monitor individual and group level skills to adequately chose a task difficulty. Additionally, each task has specific functional requirements necessary to provide an adequate user experience.

For task one the chat bot should guide users through the individual parts of the task (identifying error and correcting it) to ensure that users understand what is expected of them. Once a user attempts to solve a part of the task the application should provide immediate feedback and if necessary corrections so that the user can learn the correct solution to the task.

The second task requires that the bot chooses a new word from the list of available words which the active user should explain in the chat. If a user is tasked with explaining a word they do not know they need the option to chose a different word. This means that in providing a word to explain to a user the application additionally should provide the option to reject this word. The application should detect the use of the to-be-explained word in the chat by the user who is supposed to explain it in order to prevent this basic form of cheating in the task. The bot should in such a case mark the task as incorrectly answered. In case one of the other users correctly guesses the word the application needs to detect the solution in the chat and mark the round in the task as solved.
