---
layout: post
title: Design
sections:
 - title: Problem Description
   tag: \#problem
 - title: Market Research
   tag: \#market
 - title: Learning Scenario
   tag: \#scenario
 - title: Design Process
   tag: \#design
 - title: References
   tag: \#references
description: Learn more about the application's design and functionality.
image: pic02.jpg
---
<div id="problem"></div>
## Problem Description

### Target Group

The target group that best fit the goals of this application consists of non-native English learners. In particular, high school students who already have an upper-intermediate level of language proficiency and are about 15 years old. We took the English learning competency level as our measurement of proficiency, as defined by the Common European Framework of Reference for Languages (CEFR). We then designed our application for learners with a proficiency around the B1-B2 level. While B1 refers to an intermediate or ‘threshold’ level of language, B2 refers to an upper-intermediate level (CEFR, 2020).

After reaching the B1 Level, students are able to express und understand English sufficiently for basic interactions in a more informal environment. They are also able to produce simple, short texts about topics in which they feel familiar, and to communicate with native speakers in these topics. Therefore, one can say that students of the level B1 are able to engage and solve problems in everyday life situations (CEFR, 2020). However, B1 is not sufficient to complete, for instance, a course of study or to work in an English speaking environment. English learners at level B2, on the other hand, have more advanced skills in comparison to those on a B1 level. They are able to understand the main topics of complex texts and to interact in a more flexible way, also concerning topics which are not familiar to them (CEFR, 2020).

Therefore, we expect that the target users are able to understand questions and the explanations concerning tasks and to communicate on a basic to advanced level. It is also important to note that our target group focusses on high school students at the age of 15. Thus, we are taking into consideration that they are likely to accustom to the use of smartphones and instant message applications, such as Telegram. As they are also receiving instructions in English at school, this application focusses on the practice and training of already established language skills.

<div id="market"></div>
### Results from the Market Research

In the mentioned market research we examined pre-existing applications for language learning, specifically for the learning of English. Since the goal of this project is the development of a language learning application supported by methods of Artificial Intelligence (AI), more specifically, Adaptive Language Learning (ALL), we were even more interested in the use of AI and ALL tools in those applications.

According to our market research, the most important gap is to be found in applications that focus on group learning scenarios. Specifically, on learning environments, in which one is fully dependent on the other group members to fulfill a task. This is interesting as learning in groups, also described as cooperative learning, can have positive influences on learning languages (Zhang, 2010). We also found that, so far, there is no application using an environment that relies entirely on conversational learning and not only e.g. a click-a-button method. While there are applications that used methods of machine learning and conversational agents, we did not find any that also relied on group learning. Furthermore, we also did not find group learning environments that support conversations and communication among learners or between learners and a bot.

This concluded that for our application it is important to design tasks that, on the one hand, use the benefits from group learning and, on the other hand, enforce a natural communication to practice those skills for the learners. To foster the group learning scenario and give the learners an opportunity to benefit thereof, it is important that we create tasks where they have to engage with each other and rather than merely working on their own. The possibility for cheating behavior should also be minimized. To create the opportunity for the learners to practice natural communication, the task coordination is performed by the bot through a conversation with the learners. This communication should look as natural as possible to the students. Moreover, It is also important to support constant communication between the bot and the learner and with other learners.

Gamification, as also seen in many other applications, is an important part of successfully learning a second language, outside a ‘classic’ learning environment (Flores, 2015). Gamification describes the inclusion of aspects of games into a non-game environment (Flores, 2015). To enhance the motivation of our users, our tasks should be integrated into a more complex framework and should work in a game-like scenario.

Altogether, our target group corresponds to students who already posses an intermediate proficiency in English. The application should focus on the practicing of language skills, while supporting the students in a natural communication with each other and the bot.

<div id="scenario"></div>
### Learning Scenario

To make the users learn English effectively, we designed the tasks using two main scenarios; a group scenario and a narrative scenario. A group scenario provides users the environment of cooperative learning (or collaborative learning). Cooperative learning refers to a particular set of classroom techniques that encourage learner interdependence as a route to cognitive and social development (Johnson 1991). In this environment, since users with a higher level of and lower level randomly mixed, users have opportunities to act as resources for others and suppose a more active role in learning (Mary 1989). Those who have a higher level could learn by teaching others. For example, in task 2 where one person has to explain about a given word to the others in the group, users should try to describe the word even though they already get used to it. In the process, users need to recall the definition, consider a situation where those words would be used, and ensure their understanding of English. On the other hand, those how have a lower level could improve their English by practicing in various random conversational situations.  

In this cooperative learning situation, users will be given a common goal and work together to get the goal. In the meantime, users will be able to support each other and get social interaction which is not a common function other language learning applications could provide. According to research at Sakarya University (Bahrani & Sim 2012), social interaction is a crucial source of language learning which can occur outside of the classroom setting. Furthermore, by cooperating together, users could feel to be engaged with each other. As Astin said, the best learning environment for higher education is one in which it is possible to increase engagement (Astin 1984).

The second method we used to make users learn a language effectively is a narrative scenario, especially an escape scenario where users are supposed to be abducted by Alien and escape by solving a few tasks together. Considering the age of our target group who can easily lose their concentration, we expected this gamification of education will help users keep interested and lessen stresses for language learning. Applying gamification in education as learning tools is a promising approach since they strengthen important skills such as problem-solving, collaboration, and communication as well as knowledge (Dicheva, Darina, et al 2015).

Moreover, given a reward, a hint of a key, of completing each task successfully, users continuously being engaged and motivated. It is largely agreed that reward is an important role in terms of creating motivation (Baranek 1996). Each time users obtain a hint of the key, they could picture where they step at among the whole story and be prompted to solve further tasks to collect remaining hints.

<div id="design"></div>
## Design Process

### Task 1 - Design Process
The aim for the first task of the study project was to create an exercise which combined discussing and working together in a group of users with revising linguistic structures in English for learners at an intermediate language level. Once again it should be highlighted that the application is targeted on the need for learners to supplement the English lessons they get in school and not to give concrete instructions and new lessons about certain topics.

So, task 1 was decided to be a sentence error correction task. In this rather technical task, one user is chosen by the bot to take a turn, which concentrates on one sentence, displayed in the chat for all users. The turn consists of firstly deciding whether the sentence is correct or incorrect and secondly, in the case of an incorrect sentence, picking the incorrect word and providing the correct alternative for it.

The idea of this type of a primarily grammar-focused task was developed out of the wish for a task which concentrates on sentence construction. As the principle of error correction by the teacher in language learning is controversially discussed (Pawlak 2014, p. 149) but a proficient learner should be able to distinguish between correct and incorrect sentences, for example while revising their own texts, we decided to integrate a form of peer-correction with the last responsibility nevertheless in one user. So, the cooperative set-up in this task is introduced by giving the group of users the opportunity to discuss their thoughts on the given sentence and possible errors and asking questions in case of difficulties while completing the task.

<img src="https://github.com/ALLUOS/ALLUOS.github.io/raw/master/assets/images/task-1-screenshot-cooperation.png" alt="Figure 1: Example of cooperation in task 1" width="500">

*Figure 1: Example of cooperation in task 1*

Peer-correction “actively involves learners in the learning and teaching process” (Balderas et al. 2018, p. 184) and has been shown to be an effective method for the improvement of a learner’s writing skills (Balderas et al. 2018, p. 184). This is what we also hope to achieve with the first task which should provide a space for discussion about the sentences in question. However, the responsibility for giving an answer was decided to be given to one user on the one hand for reasons of better coordination and avoiding chaos and on the other hand to make sure to include each user in the exercise.

Only the last instance to supervise is the bot, which corresponds to the belief in learners of the greater value of teacher feedback (Pawlak 2014, p. 149) and should give the final result and confirmation. This kind of monitoring the results of the users – who are after one successful round rewarded with a part of a password to get to the next room – should frame the interaction in the chat and encourage all users to learn from it. In addition to this, the positive feedback for successfully completed turns should work as positive reinforcement for each user.

Another point to notice about task 1 is the fact that it does not contain any explicit naming of grammar structures. The idea behind this is the training through the input of English sentences which can be seen at the edge of the use of automated explicit knowledge and implicit knowledge, pointed out by Ellis et al. (Ellis 2009, p. 342). As mentioned, it should supplement English lessons in the classroom and be a practice to strengthen the English skills.

For the concrete construction of the task, a corpus of sentences served as a source. The SCoRE Corpus of Remedial English provided sentences that are written by native English speakers, additionally annotated with grammatical categories and three difficulty levels (Chujo et al. 2015). Although this corpus does not contain errors, we chose it because it came closest to fitting our needs. We then subtracted often used sentence structures from the corpus and included them into our task to make it possible for the users to learn from example sentences by native speakers. In this way, one can understand the task as well as providing input in the target language and presenting a certain pattern that learners can pick up for their own use and understanding of the English language. The grammatical categories we chose for this purpose were adverbs, gerunds, negation, present perfect, relative clauses, subjunctive, to-infinitive, verb + preposition and verb + to-infintive.

The construction of the errors per grammatical category was then achieved by replacing the words in question in the sentence structures by alternative words which would make the sentence wrong but still point out a specific structure when corrected. One example for this would be “*She never stopped love him”, instead of loving.

For the difficulty levels of the application’s adaptive difficulty model, we simply used the predefined levels from the SCoRE corpus, while making sure that the level is appropriate for our target users by checking random sample sentences of the corpus. We decided to annotate the difficulty measure of this task with “grammar”, as the focus is on sentence structuresand more fine-grained with grammar categories for which we also used the annotations of the corpus as a basis. Of course, on cannot separate the somewhat artificial grammar-category of our difficulty model from “vocabulary”, which could also be learned and revised in this task.

The narrative to introduce users to the setting of the application and to task 1 in a following step is a science fiction story taking place in space. The users are kidnapped by an alien and try to escape from the space ship they are currently kept in. This kind of narrative and escape scenario combined with the group setting should serve as a motivation in the sense of cooperative learning: Achieving a common goal, creating positive interdependence, being able to support each other and facing a common threat are factors that should contribute to a positive learning process (Dörnyei et al. 1999, pp. 164-165).

During the creation of task 1, we reached some limitations and problems that we solved with respect to time and resource constraints but that could still be improved. The sentence correction task should give room for discussions as the overall idea of the application is establishing remote collaborative learning. This has been shown not to be used much by users, so the interaction guided by the bot could point more into that direction and invite users to discuss. The construction of errors could be more naturally based on often committed mistakes by learners which was only partly possible for us to construct in the given time and setting. Other tasks focussing on grammar topics important for the target group should be added which also focus on building sentences, not only revising them.


### Task 2 - Design Process

For task 2, the goal was to come up with an activity that, just like Task 1, gives users a chance to interact with one another. The other goal was to help users in another aspect of language learning than Task 1. In Task 1, users focus on grammatical error detection, and in Task 2, they are supposed to work on vocabulary learning.

For that, a word guessing task was designed in which each user is given a word within a certain difficulty level, and he/she is supposed to describe it and what it means to the other people in the group in order for them to guess the word. In case the person whose turn is up doesn’t know the meaning of the word given to him/her, there is an option to choose an alternate word. And in case each user successfully describes the word and other users guess it correctly, one round of the game is over, and according to the narration of the game, they unlock one part of the passcode to exit the escape room.

Finally, the task is timed so that participants do not have the chance to cheat (check the definition of the words outside of the game), and the pace is fast enough to keep the game exciting.

This task was designed in order to enhance vocabulary knowledge of language learners and for them to collaboratively expand their vocabulary. For it, the design group had to create a dataset of words that are appropriate for CEFR B1-B2 English learners of approximately 15 years old. These words were extracted from Cambridgeenglish.org that were divided according to their relevant topics into 11 subcategories. These topics were then translated into seven subskills obtained from Wordnet (Free_time, Humanities, Society, Nature and science, Ailment, Body and soul, and Home and building).

The next challenge was to categorize these words according to their difficulty level, which was not given in the dataset as in Task 1. Group 2, therefore, had to come up with features that helped them in determining word difficulty. One of the indicators of word difficulty is word length(Leroy et al., 2014) – short words tend to be easier to read. This feature could be easily computed by only relying on the list of words. However, word length does not cover all of the difficulty definition for a word.

Another feature that was helpful in measuring word difficulty was the number of word senses (Medero, & Ostendorf, 2009). This could not be inferred from the list of words alone and required an extra resource for which we used Wordnet. We extracted the number of senses each word had in Wordnet. This feature was negatively correlated with word difficulty (the more meanings a word has, the easier it usually is). However, this feature also had exceptions and in and of itself, was not sufficient to measure word difficulty.

The most prominent feature that was used in different studies to estimate word difficulty was word frequency (Chen & Detmar 2016; Rudell, 1993). This, by far, was the most difficult feature to extract as well because it required a large enough and widespread - among different topics - corpus to show a reliable result for word frequency within a language. For that, we used SUBTLEX US corpus and measured word frequency based on that. This feature was also negatively correlated with word difficulty.

With these three metrics, we now had to find a way to calculate word difficulty accordingly. Since the importance of each of these features in estimating word difficulty were not equal, we needed to find out to what extent each metric contributes to word difficulty. For that, these metrics needed to have non-equal weights for making a final unified measure for word difficulty. However, we didn’t know what weight to give to each of them.

To find their weights, we created a hand-labeled small training set of these words chosen randomly to run a neural network over and find the proper weights for each of the above-mentioned features. As we expected, the highest weight was for word frequency, the second weight was for word length, and the least contributing feature to difficulty estimation was the number of senses. In the next step, we normalized all three of these features’ original values and then computed the sum of the weighted values (subtracting for the negatively correlated features). The resulting weighted sum became our final metric for word difficulty. We sorted the words according to this metric, and based on the three-level difficulty that we had in Task 1, we divided this sorted list into three difficulty levels.

Of course, we should keep in mind that this difficulty estimation does not result in 100% accurate categorization. One prominent counterexample is the word “businesswoman” that is low in frequency and is a rather long word, has only one entry in Wordnet, and according to all these measurements, it should be categorized as a difficult word (difficulty level 3). However, it is actually a rather easy word. This indicates that there is room for improvement, and semantic features of words (like difficulty) are not easily quantifiable by word’s formal features.

## Task 3 - Design Process

In review of the intermediate results from semester one of the study project, we decided to design and implement one additional task during the second semester, which includes a number of aspects to complement the first two tasks and approaches the aim of the group application further.

As described in the results of the market research in semester one, our goals for the application include tasks which benefit from group learning and encourage English communication between learners which is essential for practicing language skills. 

Secondly, for this new task, we wanted to focus on language production and writing skills as the first two tasks don’t necessarily require users to write in whole sentences (see Evaluation / Outlook).

Thirdly, resulting from what was observed in the first semester, the goal was to allow for more direct and natural communication of the users instead of a sequential task pattern. Interaction between the individuals should inspire discussions among users in English and help them practice and advance their skills together.
For these reasons in short the aim for the third task is to stimulate and to guide a discussion between users concerning a certain topic.

As progress in the communicative competence of the learners is the main requested outcome of this third task, the Communicative Approach to language learning, also called Communicative Language Teaching or Functional Approach (Jin, 2008), served as the basis for the design and the idea of the discussion task. An important aspect of the Communicative Approach is the focus on meaning in contrast to structure (Jin, 2008). Learners are emboldened to interact with each other for example in dialogues in order to fulfil a task. The primary centre of attention is therefore the function and not the accuracy of language (Jin, 2008). The developed linguistic skills within this functional dynamic can be recalled by the learners in situations requiring similar abilities with a higher likelihood then (Barson, 1993). 

Following the manner of content-based language teaching, in which non-linguistic content is taught to students through the use of language as a medium and the language is thereby learned by using it more than by studying about it (Roy Lyster, 2018), the input for the discussion task is a short text with information about a specific topic in different areas. These areas cover the different domains which were already used for the vocabulary subskill categorization during the vocabulary task. After this short input, the users are invited to discuss the topic, guided by three questions.

### Task Flow

In the following, the task flow will be presented in more detail. A correspondent flow chart can be found in the implementation section. 

In the first step the reading material is presented to the users in a short text. The goal of the text input on the one hand is to give an introduction to a topic which users might not have been in contact with, yet, and offer background knowledge for the discussion. On the other hand, the text supports the learner’s context-related vocabulary. In contrast to the vocabulary task, it is now the input itself that uses vocabulary in context and not the user who has to give the context. This way, English learners are already presented with example uses of words and phrases. Additionally, as Sternberg argues, vocabulary learning from context may not be more efficient but more permanent and stable and is central to most everyday learning settings (Sternberg 1987). The introductory text is explicitly short to be easily read from a telegram chat and not to be overwhelming for the learners.

Subsequently, a first discussion question is presented to the users. These questions allow for different opinions on the topic and should stimulate the exchange of these. After a time limit is reached, the completion criteria for the task will be checked and updated (see Completion Metrics) and the next question will be prompted to view the topic from another angle. This procedure continues in a loop until the third question is reached. The diversity of questions allows for a bit more reserve from users who might have problems to answer one of them because they can in the following contribute more for another question. 
A final poll about the user’s opinion closes the topic (see Completion Metrics). 

### Theoretical framework

A great number of existing studies have appraised the role played by discussion tasks in second/foreign language acquisition. In the introduction to this section, we explained the motivations and intentions that led us to develop a discussion task. We wanted to build a space for our users to interact more freely among each other, and prior research suggests that group discussion relaxes the stress on the learners because the focus is not on getting a specific target exercise right, but rather on communicating more generally (Puspitasari 2016). Naturally, a number of specific design choices had to be made when deciding how to tailor a discussion task to our specific learning environment. In this section we will review the literature that informed each of these choices.

As already noted, we wanted this task to enhance language production skills. Discussions are a staple of classroom teaching, not only in the context of second language learning. However, discussions are critical for language learners especially (Knight 2014). Discussions provide opportunities to produce language in contextualized and purposeful ways: learners can practice applying form (e.g., grammar, vocabulary) and function (e.g., language used to clarify, explain, argue) to communicate and build ideas. Moreover, learners benefit from redundancy of ideas and the vocabulary associated with them: discussion allows for multiple opportunities to hear new concepts and content continuously explained, analyzed, and interpreted. Furthermore, discussions via written communication have been likened to the immersive experience of studying abroad (Oliva & Pollastrini 1995), notoriously effective for language learning.

A number of authors have recognized that group discussions are facilitated by an online learning environment. “Electronic communication”, as it used to be called, has been integrated into the second language classroom ever since the 1980s ( Warschauer 1996). Most relevant for us, several studies and reports have indicated that computer-assisted classroom discussions are great equalizers of student participation (Beauvois 1992, Kelm 1992, Kern 1995, Sullivan & Pratt 1996). Among the recognized merits of online discussions, we find that it lowers the  affective filter associated with student production (Beauvois 1997), that it improves motivation (Oliva & Pollastrini 1995), and that it favors greater syntactic complexity (Kern 1995) compared to in-person discussions.

The inclusion of an initial text prompt is meant to address one of the shortcomings of group discussions pointed out in the literature, namely that insufficient content knowledge is a key issue which inhibits students’ active participation (Han 2007). Furthermore, the inclusion of guiding follow-up questions is meant to frame the bot as a discussion facilitator: effective discussion facilitation is one of the key skills required for teachers who want to conduct fruitful discussions in class (Brown 2001).

N.B. to-do: update references, add mention of Ardianti (2017).

### Materials

### Completion Metrics

 The goal of the “Discussion Task” is to motivate users to converse and make sentences around certain topics, to use grammar and vocabulary as well as expressing their opinions in the second language they are learning (English here). Here, the goal is not perfect grammar or complicated or highly technical vocabulary. The goal, however, is to make a clear, understandable conversation and be able to understand what others say and express one’s own opinion. Another goal is to generate sentences and through that, become more proficient in expressing oneself in the second language. So in short, language comprehension and expression are the goals of the discussion task.

With these goals in mind and since the users’ outputs in this task, compared to the previous two tasks (sentence correction and vocabulary guessing) are less quantifiable, we needed to define a set of metrics to decide when the task is done and whether it is done successfully or not.

Therefore, for the completion metrics of this task, we came up with the following items:

Each user must contribute a minimum number of words to the topic in discussion. This minimum number was decided as 100 words. This could be distributed among the three topic questions that are given to the users. Hence, the next metric.
Alongside the first metric, we set another requirement for considering the task as successfully done, and that is, if the users participate in the discussion of at least 2 out of 3 topic questions offered to them. This and the previous metric together, assess group performance in terms of active participation of each user and whether they take part in the discussion actively rather than being passive observers.
Another metric for considering the task as successfully completed is the overall number of words all the participants use during a round of the task. Given the minimum number of words for each user is 100 words, this number would add up to 400 words for the whole group(since the group consists of four participants).
And finally, we ask for user feedback at the end of each round and ask them for their evaluation of the group performance. This score scales between 0 to 5, five being the highest score for the group performance. This metric gives us a self-report from the users, which in turn, gives us an estimate of how well everyone performed in the group according to their individual evaluation. The group mean score will be considered finally. The participants do not know this score is one of the indicators of their success or failure in the task and guessing would not be so easy since this is only one of the metrics out of four we have for evaluating group pass or fail. Therefore, there are no biases in giving a wrongfully high score to the group performance.

These metrics might not give us a good understanding of the group performance individually. But when assembled in a logical order, depending on the impact each has in the evaluation of the group performance, they can make more sense. What we consider as minimally successful completion of the task is when each user has generated at least 100 words or at least participated in 2 out of 3 topic questions and the whole group generated at least 400 words and their overall rating of the group performance is equal or above 3.



The table below depicts the above description in a more structured manner.



<p align="center">
Completion Metrics
</p>

| Metrics | Pass | Fail |
| ---- | ---- | ---- |
 | A. What is your overall rating of the group performance in this task? (5 being the best)| Average score >= 3 - Task is completed | Average score < 3 - Task is not completed |
 | B. Number of the generated words (overall) | >= 400- Task is completed | < 400 - Task is not completed |
 | C. Number of the words each user generated during the task | >= 100 - Task is completed | < 100 - Task is not completed|
 | D. Participation in at least two topic questions | >= 2 - Task is completed | < 2 - Task is not completed |




And the following formula depicts how we came up with a logical way to determine a completed task as successful or failed:
<p align="center">
 A & B & (C | D)
 </p>

Which translates to:

**Overall rating of the group performance  & Number of overall generated words  & 
( Number of words each user generated  |  Participation in at least two topic questions )**


In addition, there is a time limit to the task and each topic question being asked and answered, to make the it manageable and engage users to participate within a limited time frame. This time frame was defined as 5 minutes for each topic question and at the end of this time, the bot prompts the group whether they are finished with the discussion or they would like to continue the conversation (because they have not yet finished discussing the question at hand). At this point, if the participants reply that the conversation has ended, they are prompted with the next topic question (or if that was the last question, the task ends). Otherwise, the time for the current question is extended so that they can bring the discussion to an end. 

### Outlook

We think that the discussion task is a great new feature of our application and a nice addition to the first two tasks. This could even be further developed in the future.

Possible future extensions of the task can include messages from the bot to discuss with users. An advantage of these contributions to the discussion can be more guidance and the effect of “model answers” which can serve for less experienced English speakers as an orientation. This also includes examples for the use of discussion phrases which can add to the learning effect. 

Another additional feature can be corrections and helpful hints by the bot. Meanwhile, the bot should be similar as Barson (1993) describes the teacher in a similar classroom setting: only play a supportive role and help discreetly to identify errors while mostly appreciating the learner’s contributions.

Furthermore, vocabulary hints and short descriptions of words which are possibly new to the learners would be a valuable addition. This way probably an even bigger vocabulary learning effect could be achieved.


## Summary of Functional Requirements

In summary, the chat bot should provide functionality for a group interaction in which 15 to 16 year old students (language level B1) can train their communication skills in the English language outside of a school setting. This requires that users can form and/ or join groups of up to four members when using the application. Generally, the chat bot should in its interaction with the users use language and task descriptions that match the B1 language level of the target group. Additionally, gamification is included in the design of the application. The chat bot needs to track users' progress in solving the tasks and provide them with clear feedback and rewards when tasks are successfully completed to further motivate and engage them. Once the group has been formed the application needs to allow users to chose one of the two developed tasks.

Detailed functional requirements follow from the in-depth description of the two developed tasks provided above. For both tasks it is necessary that each user is chosen in turn as the main active user, who either attempts to correct the sentence (task one) or provides a description for the current word (task two). This means that the application needs to track which users have already performed the task in any given round and select a new user for each turn. The application should model users' skill level for relevant language components: vocabulary (trained through task two) and grammar (trained through task one). Each of these broad language components is represented through a set of specific sub-skills. Performing the tasks should train some of these sub-skills and the application needs to monitor individual and group level skills to adequately chose a task difficulty. Additionally, each task has specific functional requirements necessary to provide an adequate user experience.

For task one the chat bot should guide users through the individual parts of the task (identifying error and correcting it) to ensure that users understand what is expected of them. Once a user attempts to solve a part of the task the application should provide immediate feedback and if necessary corrections so that the user can learn the correct solution to the task.

The second task requires that the bot chooses a new word from the list of available words which the active user should explain in the chat. If a user is tasked with explaining a word they do not know they need the option to chose a different word. This means that in providing a word to explain to a user the application additionally should provide the option to reject this word. The application should detect the use of the to-be-explained word in the chat by the user who is supposed to explain it in order to prevent this basic form of cheating in the task. The bot should in such a case mark the task as incorrectly answered. In case one of the other users correctly guesses the word the application needs to detect the solution in the chat and mark the round in the task as solved.


<div id="references"></div>
### References

Astin, A. W. (1984). Student involvement: A developmental theory for higher education. Journal of college student personnel, 25(4), 297-308.

Bahrani, T., & Sim, T. S. (2012). Informal Language Learning Setting: Technology or Social Interaction?. Turkish Online Journal of Educational Technology-TOJET, 11(2), 142-149.

Balderas, I. and Guillén Cuamatzi, P. (2018). Self and Peer Correction to Improve College Students’ Writing Skills. In Profile: Issues Teachers’ Professional Development 20(2) (pp. 179-194). https://doi.org/10.15446/profile.v20n2.67095

Baranek, L. K. (1996). The effect of rewards and motivation on student achievement.

Barson, J., Frommer, J. & Schwartz, M. (1993). Foreign Language Learning Using E-Mail in a Task-Oriented Perspective: Interuniversity Experiments in Communication and Collaboration. Journal of Education and Technology, 2 (4), 565-584.

CEFR (Common European Framework for Reference of Language) 2020, Global scale - Table 1 (CEFR 3.3): Common Reference levels. https://www.coe.int/en/web/common-european-framework-reference-languages/table-1-cefr-3.3-common-reference-levels-global-scale

Chen, Xiaobin & Meurers, Detmar. (2016). Characterizing Text Difficulty with Word Frequencies. 84-94. 10.18653/v1/W16-0509.

Chujo, K., Oghigian, K. and Akasegawa, S. (2015). A corpus and grammatical browsing system for remedial EFL learners. In A. Leńko-Szymańska and A. Boulton (eds.), Multiple Affordances of Language Corpora for Data-driven Learning (pp. 109-128). Amsterdam: John Benjamins.

Dicheva, D., Dichev, C., Agre, G., & Angelova, G. (2015). Gamification in education: A systematic mapping study. Journal of Educational Technology & Society, 18(3).

Dörnyei, Z. and Malderez, A. (1999). The role of group dynamics in foreign language learning and teaching. In J. Arnold (ed.). Affect in Language Teaching. Cambridge University Press (pp. 155-169).

Ellis, R. et al. (2009). Implicit and Explicit Knowledge inSecond Language Learning, Testing and Teaching. Bristol: Multilingual Matters.

Flores, J. F. F. (2015). Using gamification to enhance second language learning. Digital Education Review, (27), 32-54.

Jin, G. (2008). Application of Communicative Approach in College English Teaching. Asian Social Science, 4 (4), 81-85.

Johnson, D. W. (1991). Cooperative Learning: Increasing College Faculty Instructional Productivity. ASHE-ERIC Higher Education Report No. 4, 1991. ASHE-ERIC Higher Education Reports, George Washington University, One Dupont Circle, Suite 630, Washington, DC 20036-1183.

Leroy, G., & Kauchak, D. (2014). The effect of word familiarity on actual and perceived text difficulty. Journal of the American Medical Informatics Association : JAMIA, 21(e1), e169–e172. https://doi.org/10.1136/amiajnl-2013-002172

Lyster, R. (2018). Content-Based Language Teaching. New York: Routledge.

Mary McGroarty (1989) The Benefits of Cooperative Learning Arrangements in Second Language Instruction, NABE Journal, 13:2, 127-143, DOI: 10.1080/08855072.1989.10668555

Medero, Julie & Ostendorf, Mari. (2009). Analysis of vocabulary difficulty using Wiktionary. SLaTE: 61-64

Pawlak, M. (2014). Error Correction in the Foreign Language Classroom. Reconsidering the Issues. Springer-Verlag Berlin Heidelberg.

Rudell, A. P. (1993). Frequency of word usage and perceived word difficulty: Ratings of Kučera and Francis words. Behavior Research Methods, Instruments & Computers, 25(4), 455–   463. https://doi.org/10.3758/BF03204543

Sternberg, R. J.(1987): Most Vocabulary is Learned From Context. In: M. G. McKeown & M. E. Curtis (Eds.) The Nature of Vocabulary Acquisition (pp. 89-106). New York, London: Psychology Press.

Zhang, Y. (2010). Cooperative language learning and foreign language learning and teaching. Journal of Language Teaching and Research, 1(1), 81-83.
